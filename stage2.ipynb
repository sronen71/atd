{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import timm\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import albumentations\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.cuda.amp as amp\n",
    "from torch.utils.data import  Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 20, 8\n",
    "device = torch.device('cuda')\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = '0920_1bonev2_effv2s_224_15_6ch_augv2_mixupp5_drl3_rov1p2_bs8_lr23e5_eta23e6_50ep'\n",
    "load_kernel = None\n",
    "load_last = True\n",
    "\n",
    "n_folds = 5\n",
    "#backbone = 'tf_efficientnetv2_s.in21k_ft_in1k'\n",
    "#backbone=\"tf_efficientnetv2_b3.in21k_ft_in1k\"\n",
    "backbone=\"tf_efficientnetv2_b2.in1k\"\n",
    "\n",
    "image_size = 296\n",
    "\n",
    "n_slice_per_c = 24 # liver,spleen,left kidney, right kidney \n",
    "in_chans = 4\n",
    "\n",
    "init_lr = 2.5e-4\n",
    "eta_min = 1e-7\n",
    "batch_size = 3\n",
    "drop_rate = 0.\n",
    "drop_rate_last = 0.2 #  0.1\n",
    "drop_path_rate = 0.2\n",
    "p_mixup = 0.5 #0 0.3\n",
    "p_rand_order_v1 = 0.2\n",
    "\n",
    "data_dir = './preprocessed2'\n",
    "use_amp = True\n",
    "num_workers = 6\n",
    "out_dim = 3\n",
    "\n",
    "n_epochs = 60\n",
    "\n",
    "log_dir = './logs'\n",
    "model_dir = './models_cls'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sronen/code/.venv/lib/python3.10/site-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "border_mode=cv2.BORDER_CONSTANT\n",
    "transforms_train = albumentations.Compose([\n",
    "    albumentations.Resize(image_size, image_size),\n",
    "    #albumentations.HorizontalFlip(p=0.3),\n",
    "    #albumentations.VerticalFlip(p=0.3),\n",
    "    #albumentations.Transpose(p=0.3),\n",
    "    #albumentations.RandomBrightnessContrast(brightness_limit=0.05, contrast_limit=0.05, brightness_by_max=False, always_apply=False, p=0.3),\n",
    "\n",
    "    #border_mode=cv2.BORDER_REFLECT101\n",
    "    albumentations.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=15, border_mode=border_mode, p=0.5),\n",
    "\n",
    "    #albumentations.OneOf([\n",
    "    #    albumentations.MotionBlur(blur_limit=3),\n",
    "    #    albumentations.MedianBlur(blur_limit=3),\n",
    "    #    albumentations.GaussianBlur(blur_limit=(1,3)),\n",
    "    #    albumentations.GaussNoise(var_limit=(3.0, 9.0)),\n",
    "    #], p=0.5),\n",
    "    #albumentations.OneOf([\n",
    "        #albumentations.OpticalDistortion(distort_limit=.3),\n",
    "    #    albumentations.GridDistortion(num_steps=4, distort_limit=.2),\n",
    "    #], p=0.3),\n",
    "    albumentations.GridDistortion(num_steps=4, distort_limit=.3),\n",
    "    albumentations.Cutout(max_h_size=int(image_size * 0.3), max_w_size=int(image_size * 0.3), num_holes=1, p=0.4),\n",
    "])\n",
    "\n",
    "transforms_valid = albumentations.Compose([\n",
    "    albumentations.Resize(image_size, image_size),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>c</th>\n",
       "      <th>hu</th>\n",
       "      <th>label</th>\n",
       "      <th>label1</th>\n",
       "      <th>fold</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14123</th>\n",
       "      <td>9961</td>\n",
       "      <td>63032</td>\n",
       "      <td>2</td>\n",
       "      <td>143.75</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14124</th>\n",
       "      <td>9980</td>\n",
       "      <td>40214</td>\n",
       "      <td>0</td>\n",
       "      <td>103.00</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14125</th>\n",
       "      <td>9980</td>\n",
       "      <td>40214</td>\n",
       "      <td>1</td>\n",
       "      <td>103.00</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14126</th>\n",
       "      <td>9980</td>\n",
       "      <td>40214</td>\n",
       "      <td>2</td>\n",
       "      <td>103.00</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14127</th>\n",
       "      <td>9980</td>\n",
       "      <td>40466</td>\n",
       "      <td>0</td>\n",
       "      <td>135.00</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14128</th>\n",
       "      <td>9980</td>\n",
       "      <td>40466</td>\n",
       "      <td>1</td>\n",
       "      <td>135.00</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14129</th>\n",
       "      <td>9980</td>\n",
       "      <td>40466</td>\n",
       "      <td>2</td>\n",
       "      <td>135.00</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14130</th>\n",
       "      <td>9983</td>\n",
       "      <td>10806</td>\n",
       "      <td>0</td>\n",
       "      <td>168.00</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14131</th>\n",
       "      <td>9983</td>\n",
       "      <td>10806</td>\n",
       "      <td>1</td>\n",
       "      <td>168.00</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14132</th>\n",
       "      <td>9983</td>\n",
       "      <td>10806</td>\n",
       "      <td>2</td>\n",
       "      <td>168.00</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       patient_id  series_id  c      hu      label  label1  fold  counts\n",
       "14123        9961      63032  2  143.75  [1, 0, 0]       0     2       2\n",
       "14124        9980      40214  0  103.00  [1, 0, 0]       0     2       2\n",
       "14125        9980      40214  1  103.00  [0, 0, 1]       2     2       2\n",
       "14126        9980      40214  2  103.00  [1, 0, 0]       0     2       2\n",
       "14127        9980      40466  0  135.00  [1, 0, 0]       0     2       2\n",
       "14128        9980      40466  1  135.00  [0, 0, 1]       2     2       2\n",
       "14129        9980      40466  2  135.00  [1, 0, 0]       0     2       2\n",
       "14130        9983      10806  0  168.00  [1, 0, 0]       0     1       1\n",
       "14131        9983      10806  1  168.00  [0, 0, 1]       2     1       1\n",
       "14132        9983      10806  2  168.00  [1, 0, 0]       0     1       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "organ_dict = {\n",
    "    0: 'liver',\n",
    "    1: 'spleen',\n",
    "    2: 'kidney',\n",
    "}\n",
    "\n",
    "df_p = pd.read_csv('/kaggle/input/rsna-2023-abdominal-trauma-detection/train.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_s=pd.read_csv('/kaggle/input/rsna-2023-abdominal-trauma-detection/train_series_meta.csv')\n",
    "\n",
    "df_p['fold'] = -1\n",
    "kf = KFold(5,shuffle=True,random_state=42)\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(df_p,df_p)):\n",
    "    df_p.loc[valid_idx, 'fold'] = fold\n",
    "\n",
    "\n",
    "#df_healthy=df_p[df_p[\"any_injury\"]==0].sample(758)\n",
    "#df_injured=df_p[(df_p[\"kidney_healthy\"]==0) | (df_p[\"liver_healthy\"]==0)| (df_p[\"spleen_healthy\"]==0) | (df_p[\"bowel_healthy\"]==0)]\n",
    "#print(len(df_injured),len(df_healthy))\n",
    "#df_p1=pd.concat((df_healthy,df_injured))\n",
    "\n",
    "\n",
    "df=df_p.merge(df_s,on=\"patient_id\")\n",
    "df[\"count\"]=df.groupby([\"patient_id\"])[\"patient_id\"].transform(\"count\")\n",
    "\n",
    "\n",
    "pid=[]\n",
    "sid = []\n",
    "cs = []\n",
    "label = []\n",
    "label1=[]\n",
    "fold = []\n",
    "hu=[]\n",
    "counts=[]\n",
    "for row in df.to_dict(orient=\"records\"):\n",
    "    for i in [0,1,2]:\n",
    "        pid.append(row[\"patient_id\"])\n",
    "        sid.append(row[\"series_id\"])\n",
    "        cs.append(i)\n",
    "        hu.append(row[\"aortic_hu\"])\n",
    "        organ=organ_dict[i]\n",
    "        la=[row[f'{organ}_healthy'],row[f'{organ}_low'],row[f'{organ}_high']]\n",
    "        label.append(la)\n",
    "        label1.append(np.argmax(la))\n",
    "        fold.append(row[\"fold\"])\n",
    "        counts.append(row[\"count\"])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'patient_id': pid,\n",
    "    'series_id': sid,\n",
    "    'c': cs,\n",
    "    'hu':hu,\n",
    "    'label': label,\n",
    "    'label1':label1,\n",
    "    'fold': fold,\n",
    "    'counts':counts,\n",
    "})\n",
    "\n",
    "df = df.sample(16).reset_index(drop=True) if DEBUG else df\n",
    "\n",
    "df.tail(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLSDataset(Dataset):\n",
    "    def __init__(self, df, mode, transform):\n",
    "\n",
    "        self.df = df.reset_index()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        cid = row.c\n",
    "        \n",
    "        images = []\n",
    "        \n",
    "        filepath=os.path.join(data_dir, f'{row.patient_id}_{row.series_id}.npz')\n",
    "        image3d = np.load(filepath)['arr_0'] # slice,channel,H,W\n",
    "        istart=n_slice_per_c*cid\n",
    "        iend=istart+n_slice_per_c\n",
    "        for ind in list(range(istart,iend)):\n",
    "            image=image3d[ind,...].transpose(1,2,0).astype(np.uint8)\n",
    "            image = self.transform(image=image)['image']\n",
    "            image = image.transpose(2, 0, 1).astype(np.float32) / 255.\n",
    "            images.append(image)\n",
    "        images = np.stack(images, 0)\n",
    "\n",
    "   \n",
    "\n",
    "        if self.mode != 'test':\n",
    "            images = torch.tensor(images).float()\n",
    "            labels = torch.tensor([row.label] * n_slice_per_c).float()\n",
    "            counts=torch.tensor([row.counts]*n_slice_per_c).float()\n",
    "            \n",
    "            #images[...]=0.\n",
    "            #images[:,:,:,:3]=labels[:,None,None,:]\n",
    "            #images[:,0,0,:3]=labels[:,:]\n",
    "\n",
    "         \n",
    "            \n",
    "            if self.mode == 'train' and random.random() < p_rand_order_v1:\n",
    "                indices = torch.randperm(images.size(0))\n",
    "                images = images[indices]\n",
    "                counts=counts[indices]\n",
    "\n",
    "            return images, labels,counts\n",
    "        else:\n",
    "            return torch.tensor(images).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 20,8\n",
    "\n",
    "df_show = df\n",
    "dataset_show = CLSDataset(df_show, 'train', transform=transforms_train)\n",
    "loader_show = torch.utils.data.DataLoader(dataset_show, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x7fddec95f880> (for post_execute):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib_inline/backend_inline.py:126\u001b[0m, in \u001b[0;36mflush_figures\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m InlineBackend\u001b[39m.\u001b[39minstance()\u001b[39m.\u001b[39mclose_figures:\n\u001b[1;32m    124\u001b[0m     \u001b[39m# ignore the tracking, just draw and close all figures\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m         \u001b[39mreturn\u001b[39;00m show(\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    127\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    128\u001b[0m         \u001b[39m# safely show traceback if in IPython, else raise\u001b[39;00m\n\u001b[1;32m    129\u001b[0m         ip \u001b[39m=\u001b[39m get_ipython()\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib_inline/backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[39mfor\u001b[39;00m figure_manager \u001b[39min\u001b[39;00m Gcf\u001b[39m.\u001b[39mget_all_fig_managers():\n\u001b[0;32m---> 90\u001b[0m         display(\n\u001b[1;32m     91\u001b[0m             figure_manager\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mfigure,\n\u001b[1;32m     92\u001b[0m             metadata\u001b[39m=\u001b[39;49m_fetch_figure_metadata(figure_manager\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mfigure)\n\u001b[1;32m     93\u001b[0m         )\n\u001b[1;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     show\u001b[39m.\u001b[39m_to_draw \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/IPython/core/display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     publish_display_data(data\u001b[39m=\u001b[39mobj, metadata\u001b[39m=\u001b[39mmetadata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     format_dict, md_dict \u001b[39m=\u001b[39m \u001b[39mformat\u001b[39;49m(obj, include\u001b[39m=\u001b[39;49minclude, exclude\u001b[39m=\u001b[39;49mexclude)\n\u001b[1;32m    299\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m format_dict:\n\u001b[1;32m    300\u001b[0m         \u001b[39m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/IPython/core/formatters.py:177\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    175\u001b[0m md \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     data \u001b[39m=\u001b[39m formatter(obj)\n\u001b[1;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[39m# FIXME: log the exception\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39;49m(extras \u001b[39m+\u001b[39;49m args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/IPython/core/formatters.py:221\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 221\u001b[0m     r \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    222\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[39m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_return(\u001b[39mNone\u001b[39;00m, args[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/IPython/core/formatters.py:338\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m     \u001b[39mreturn\u001b[39;00m printer(obj)\n\u001b[1;32m    339\u001b[0m \u001b[39m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    340\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 152\u001b[0m fig\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mprint_figure(bytes_io, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    153\u001b[0m data \u001b[39m=\u001b[39m bytes_io\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/backend_bases.py:2342\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2336\u001b[0m     renderer \u001b[39m=\u001b[39m _get_renderer(\n\u001b[1;32m   2337\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure,\n\u001b[1;32m   2338\u001b[0m         functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m   2339\u001b[0m             print_method, orientation\u001b[39m=\u001b[39morientation)\n\u001b[1;32m   2340\u001b[0m     )\n\u001b[1;32m   2341\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mgetattr\u001b[39m(renderer, \u001b[39m\"\u001b[39m\u001b[39m_draw_disabled\u001b[39m\u001b[39m\"\u001b[39m, nullcontext)():\n\u001b[0;32m-> 2342\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m   2344\u001b[0m \u001b[39mif\u001b[39;00m bbox_inches:\n\u001b[1;32m   2345\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[1;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     96\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[1;32m     97\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/figure.py:3175\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3172\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   3174\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 3175\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   3176\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   3178\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[1;32m   3179\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/axes/_base.py:3064\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[39mif\u001b[39;00m artists_rasterized:\n\u001b[1;32m   3062\u001b[0m     _draw_rasterized(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[0;32m-> 3064\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[1;32m   3065\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[1;32m   3067\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39maxes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   3068\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[1;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[1;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/axis.py:1383\u001b[0m, in \u001b[0;36mAxis.draw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m     tick\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m   1382\u001b[0m \u001b[39m# Shift label away from axes to avoid overlapping ticklabels.\u001b[39;00m\n\u001b[0;32m-> 1383\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_label_position(renderer)\n\u001b[1;32m   1384\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m   1386\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_offset_text_position(tlb1, tlb2)\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/axis.py:2565\u001b[0m, in \u001b[0;36mYAxis._update_label_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   2563\u001b[0m \u001b[39m# get bounding boxes for this axis and any siblings\u001b[39;00m\n\u001b[1;32m   2564\u001b[0m \u001b[39m# that have been set by `fig.align_ylabels()`\u001b[39;00m\n\u001b[0;32m-> 2565\u001b[0m bboxes, bboxes2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_tick_boxes_siblings(renderer\u001b[39m=\u001b[39;49mrenderer)\n\u001b[1;32m   2566\u001b[0m x, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel\u001b[39m.\u001b[39mget_position()\n\u001b[1;32m   2567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_position \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/axis.py:2099\u001b[0m, in \u001b[0;36mAxis._get_tick_boxes_siblings\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[39mfor\u001b[39;00m ax \u001b[39min\u001b[39;00m grouper\u001b[39m.\u001b[39mget_siblings(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes):\n\u001b[1;32m   2098\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(ax, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39maxis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2099\u001b[0m     ticks_to_draw \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49m_update_ticks()\n\u001b[1;32m   2100\u001b[0m     tlb, tlb2 \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n\u001b[1;32m   2101\u001b[0m     bboxes\u001b[39m.\u001b[39mextend(tlb)\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/axis.py:1262\u001b[0m, in \u001b[0;36mAxis._update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_ticks\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1258\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[39m    Update ticks (position and labels) using the current data interval of\u001b[39;00m\n\u001b[1;32m   1260\u001b[0m \u001b[39m    the axes.  Return the list of ticks that will be drawn.\u001b[39;00m\n\u001b[1;32m   1261\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1262\u001b[0m     major_locs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_majorticklocs()\n\u001b[1;32m   1263\u001b[0m     major_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmajor\u001b[39m.\u001b[39mformatter\u001b[39m.\u001b[39mformat_ticks(major_locs)\n\u001b[1;32m   1264\u001b[0m     major_ticks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_major_ticks(\u001b[39mlen\u001b[39m(major_locs))\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/axis.py:1484\u001b[0m, in \u001b[0;36mAxis.get_majorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1482\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_majorticklocs\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1483\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return this Axis' major tick locations in data coordinates.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1484\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmajor\u001b[39m.\u001b[39;49mlocator()\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/ticker.py:2136\u001b[0m, in \u001b[0;36mMaxNLocator.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   2135\u001b[0m     vmin, vmax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis\u001b[39m.\u001b[39mget_view_interval()\n\u001b[0;32m-> 2136\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtick_values(vmin, vmax)\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/ticker.py:2144\u001b[0m, in \u001b[0;36mMaxNLocator.tick_values\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2141\u001b[0m     vmin \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mvmax\n\u001b[1;32m   2142\u001b[0m vmin, vmax \u001b[39m=\u001b[39m mtransforms\u001b[39m.\u001b[39mnonsingular(\n\u001b[1;32m   2143\u001b[0m     vmin, vmax, expander\u001b[39m=\u001b[39m\u001b[39m1e-13\u001b[39m, tiny\u001b[39m=\u001b[39m\u001b[39m1e-14\u001b[39m)\n\u001b[0;32m-> 2144\u001b[0m locs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_ticks(vmin, vmax)\n\u001b[1;32m   2146\u001b[0m prune \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prune\n\u001b[1;32m   2147\u001b[0m \u001b[39mif\u001b[39;00m prune \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlower\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/ticker.py:2083\u001b[0m, in \u001b[0;36mMaxNLocator._raw_ticks\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nbins \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m   2082\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2083\u001b[0m         nbins \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mclip(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxis\u001b[39m.\u001b[39;49mget_tick_space(),\n\u001b[1;32m   2084\u001b[0m                         \u001b[39mmax\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_min_n_ticks \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m), \u001b[39m9\u001b[39m)\n\u001b[1;32m   2085\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2086\u001b[0m         nbins \u001b[39m=\u001b[39m \u001b[39m9\u001b[39m\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/axis.py:2734\u001b[0m, in \u001b[0;36mYAxis.get_tick_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2733\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_tick_space\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m-> 2734\u001b[0m     ends \u001b[39m=\u001b[39m mtransforms\u001b[39m.\u001b[39;49mBbox\u001b[39m.\u001b[39;49munit()\u001b[39m.\u001b[39;49mtransformed(\n\u001b[1;32m   2735\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxes\u001b[39m.\u001b[39;49mtransAxes \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdpi_scale_trans)\n\u001b[1;32m   2736\u001b[0m     length \u001b[39m=\u001b[39m ends\u001b[39m.\u001b[39mheight \u001b[39m*\u001b[39m \u001b[39m72\u001b[39m\n\u001b[1;32m   2737\u001b[0m     \u001b[39m# Having a spacing of at least 2 just looks good.\u001b[39;00m\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/transforms.py:479\u001b[0m, in \u001b[0;36mBboxBase.transformed\u001b[0;34m(self, transform)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[39mConstruct a `Bbox` by statically transforming this one by *transform*.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m pts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_points()\n\u001b[0;32m--> 479\u001b[0m ll, ul, lr \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(np\u001b[39m.\u001b[39;49marray(\n\u001b[1;32m    480\u001b[0m     [pts[\u001b[39m0\u001b[39;49m], [pts[\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m], pts[\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m]], [pts[\u001b[39m1\u001b[39;49m, \u001b[39m0\u001b[39;49m], pts[\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m]]]))\n\u001b[1;32m    481\u001b[0m \u001b[39mreturn\u001b[39;00m Bbox([ll, [lr[\u001b[39m0\u001b[39m], ul[\u001b[39m1\u001b[39m]]])\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/transforms.py:1498\u001b[0m, in \u001b[0;36mTransform.transform\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m   1495\u001b[0m values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_dims))\n\u001b[1;32m   1497\u001b[0m \u001b[39m# Transform the values\u001b[39;00m\n\u001b[0;32m-> 1498\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_affine(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_non_affine(values))\n\u001b[1;32m   1500\u001b[0m \u001b[39m# Convert the result back to the shape of the input values.\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[39mif\u001b[39;00m ndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/transforms.py:2423\u001b[0m, in \u001b[0;36mCompositeGenericTransform.transform_affine\u001b[0;34m(self, points)\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform_affine\u001b[39m(\u001b[39mself\u001b[39m, points):\n\u001b[1;32m   2422\u001b[0m     \u001b[39m# docstring inherited\u001b[39;00m\n\u001b[0;32m-> 2423\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_affine()\u001b[39m.\u001b[39mtransform(points)\n",
      "File \u001b[0;32m~/code/.venv/lib/python3.10/site-packages/matplotlib/transforms.py:2449\u001b[0m, in \u001b[0;36mCompositeGenericTransform.get_affine\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2447\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_b\u001b[39m.\u001b[39mget_affine()\n\u001b[1;32m   2448\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2449\u001b[0m     \u001b[39mreturn\u001b[39;00m Affine2D(np\u001b[39m.\u001b[39;49mdot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_b\u001b[39m.\u001b[39;49mget_affine()\u001b[39m.\u001b[39;49mget_matrix(),\n\u001b[1;32m   2450\u001b[0m                            \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_a\u001b[39m.\u001b[39;49mget_affine()\u001b[39m.\u001b[39;49mget_matrix()))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f, axarr = plt.subplots(2,6)\n",
    "for p in range(6):\n",
    "    idx = p * 20\n",
    "    imgs, lbl,_ = dataset_show[idx]\n",
    "    sel=7\n",
    "    axarr[0, p].imshow(255*imgs[sel][1],cmap=\"gray\")\n",
    "    axarr[1, p].imshow(imgs[sel][-1],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormedLinear(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(NormedLinear, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(in_features, out_features))\n",
    "        self.weight.data.uniform_(-1, 1).renorm_(2, 1, 1e-5).mul_(1e5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.normalize(x, dim=1).mm(F.normalize(self.weight, dim=0))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimmModel(nn.Module):\n",
    "    def __init__(self, backbone, pretrained=False):\n",
    "        super(TimmModel, self).__init__()\n",
    "\n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=in_chans,\n",
    "            num_classes=out_dim,\n",
    "            features_only=False,\n",
    "            drop_rate=drop_rate,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "\n",
    "        if 'efficient' in backbone:\n",
    "            hdim = self.encoder.conv_head.out_channels\n",
    "            self.encoder.classifier = nn.Identity()\n",
    "        elif 'convnext' in backbone:\n",
    "            hdim = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Identity()\n",
    "\n",
    "\n",
    "        self.lstm = nn.LSTM(hdim, 64, num_layers=1, dropout=drop_rate, bidirectional=True, batch_first=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(drop_rate_last),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(64, out_dim),\n",
    "            #NormedLinear(128,out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # (bs, nslice, ch, sz, sz)\n",
    "        bs = x.shape[0]\n",
    "        x = x.view(bs * n_slice_per_c, in_chans, image_size, image_size)\n",
    "        feat = self.encoder(x)\n",
    "        feat = feat.view(bs, n_slice_per_c, -1)\n",
    "        feat, _ = self.lstm(feat)\n",
    "        feat = feat.contiguous().view(bs * n_slice_per_c, -1)\n",
    "        feat = self.head(feat)\n",
    "        feat = feat.view(bs, n_slice_per_c,out_dim).contiguous()\n",
    "\n",
    "        return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = TimmModel(backbone)\n",
    "m(torch.rand(2, n_slice_per_c, in_chans, image_size, image_size)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(m,(1,n_slice_per_c,in_chans,image_size,image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LDAMLoss(nn.Module): # Label-Distribution-Aware Margin Loss\n",
    "    \n",
    "    def __init__(self, cls_num_list, max_m=0.5, weight=None, s=30):\n",
    "        super(LDAMLoss, self).__init__()\n",
    "        m_list = 1.0 / np.sqrt(np.sqrt(cls_num_list))\n",
    "        m_list = m_list * (max_m / np.max(m_list))\n",
    "        m_list = torch.cuda.FloatTensor(m_list)\n",
    "        self.m_list = m_list\n",
    "        assert s > 0\n",
    "        self.s = s\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        index = torch.zeros_like(x, dtype=torch.uint8)\n",
    "        index.scatter_(1, target.data.view(-1, 1), 1)\n",
    "        \n",
    "        index_float = index.type(torch.cuda.FloatTensor)\n",
    "        batch_m = torch.matmul(self.m_list[None, :], index_float.transpose(0,1))\n",
    "        batch_m = batch_m.view((-1, 1))\n",
    "        x_m = x - batch_m\n",
    "    \n",
    "        output = torch.where(index, x_m, x)\n",
    "        return F.cross_entropy(self.s*output, target, weight=self.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = nn.CrossEntropyLoss(reduction='none', label_smoothing=0.0)\n",
    "\n",
    "mapping = torch.tensor([1., 2., 4.]).cuda()\n",
    "mapping=mapping/torch.mean(mapping)\n",
    "\n",
    "def criterion(logits, targets,counts=None,weights=None):\n",
    "    b=logits.shape[0]\n",
    "    logits=logits.view(-1,out_dim)\n",
    "    targets=targets.view(-1,out_dim)\n",
    "    loss = ce(logits, targets)\n",
    "    ll=torch.argmax(targets,dim=1) \n",
    "    #print(\"logits\",logits[0:5,:],\"targets\",ll[0:5])\n",
    "\n",
    "    #0->1,1->2,2->4 \n",
    "\n",
    "# Use torch.index_select to apply the mapping\n",
    "    #w = torch.index_select(mapping, dim=0, index=ll)\n",
    "    if weights is not None:\n",
    "        w=torch.matmul(targets,mapping)\n",
    "    else:\n",
    "        w=torch.ones(b).float().cuda()\n",
    "    if counts is not None:\n",
    "        counts=counts.view(-1)\n",
    "        w=w/counts\n",
    "    loss=loss.reshape((b,-1))\n",
    "    w=w.reshape((b,-1))\n",
    "    loss=torch.mean(loss,dim=1)\n",
    "\n",
    "    w=torch.mean(w,dim=1)\n",
    "    return loss,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.beta import Beta\n",
    "beta=Beta(torch.tensor([0.2]),torch.tensor([0.2]))\n",
    "\n",
    "def mix_up(images1,labels1):\n",
    "    # Unpack two datasets\n",
    "    batch_size = images1.shape[0]\n",
    "    # Sample lambda and reshape it to do the mixup\n",
    "    l = beta.sample(torch.Size([batch_size])).cuda()\n",
    "    x_l = l.reshape((batch_size, 1, 1, 1,1))\n",
    "    y_l = l.reshape((batch_size, 1,1))\n",
    "    idx = torch.randperm(batch_size).cuda()\n",
    "    images2=images1[idx,...]\n",
    "    labels2=labels1[idx,...]\n",
    "    # Perform mixup on both images and labels by combining a pair of images/labels\n",
    "    # (one from each dataset) into one image/label\n",
    "    images = images1 * x_l + images2 * (1 - x_l)\n",
    "    labels = labels1 * y_l + labels2 * (1 - y_l)\n",
    "    return (images, labels)\n",
    "\n",
    "\n",
    "def train_func(model, loader_train, optimizer, scaler=None):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    ws=[]\n",
    "    bar = tqdm(loader_train)\n",
    "    for images, targets,_ in bar:\n",
    "        optimizer.zero_grad()\n",
    "        images = images.cuda()\n",
    "        targets = targets.cuda()\n",
    "  \n",
    "        if random.random() < p_mixup:\n",
    "            images, targets = mix_up(images, targets)\n",
    "\n",
    "        if use_amp:\n",
    "            with amp.autocast():\n",
    "                logits = model(images)\n",
    "                loss,w = criterion(logits, targets)\n",
    "                loss1=torch.mean(loss*w)\n",
    "            scaler.scale(loss1).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            train_loss.extend(loss.detach().cpu())\n",
    "\n",
    "        else:\n",
    "            logits = model(images)\n",
    "            loss,w = criterion(logits, targets)\n",
    "            loss1=torch.mean(loss*w)\n",
    "            loss1.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.extend(loss.detach().cpu())\n",
    "\n",
    "            \n",
    "        ws.extend(w.detach().cpu())\n",
    "        bar.set_description(f'smth:{np.average(train_loss[-100:],weights=ws[-100:]):.4f}')\n",
    "\n",
    "    return np.average(train_loss,weights=ws)\n",
    "\n",
    "\n",
    "def valid_func(model, loader_valid,dff):\n",
    "    model.eval()\n",
    "    valid_loss=[]\n",
    "    valid_loss_progress = []\n",
    "    outputs = []\n",
    "    tgs=[]\n",
    "    ws=[]\n",
    "    ws_progress=[]\n",
    "    bar = tqdm(loader_valid)\n",
    "    with torch.no_grad():\n",
    "        for images, targets,counts in bar:\n",
    "            images = images.cuda()\n",
    "            targets = targets.cuda()\n",
    "            counts=counts.cuda()\n",
    "\n",
    "            #if use_amp:\n",
    "            #    with amp.autocast():\n",
    "            \n",
    "            logits = model(images)\n",
    "            blogits=torch.mean(logits,dim=1) # average logits across slices\n",
    "            loss,w=criterion(logits,targets,counts,mapping)\n",
    "\n",
    "            ws_progress.extend(w.cpu())\n",
    "            valid_loss_progress.extend(loss.cpu())\n",
    "            out=torch.unbind(blogits,dim=0)   \n",
    "            outputs.extend(out)\n",
    "            tt=targets[:,0,:] # first slice\n",
    "            tgs.extend(torch.unbind(tt,dim=0))\n",
    "            bar.set_description(f'smth:{np.average(valid_loss_progress[-100:],weights=ws_progress[-100:]):.4f}')\n",
    "        for pid in dff[\"patient_id\"].unique():\n",
    "            for c in range(3):\n",
    "                #print(\"patient\",pid,\"organ\",c)\n",
    "                inds=dff[(dff[\"patient_id\"]==pid) & (dff[\"c\"]==c)].index.values\n",
    "                #print(pid,c,inds[0],dff.iloc[inds[0]])\n",
    "                la=torch.mean(torch.stack([outputs[i] for i in inds]),dim=0) # average logits across up to two series per patient\n",
    "                ta=tgs[inds[0]]\n",
    "\n",
    "                loss = ce(la[None,:], ta[None,:])\n",
    "                #print(\"fpatient id {pid}, organ {c}, {la} , {ta}, {loss}\")\n",
    "                valid_loss.append(loss.item())\n",
    "                ta=torch.argmax(ta)\n",
    "                w=mapping[ta].item()\n",
    "                #print(ta.item(),dff.iloc[inds[0]][\"label1\"])\n",
    "                assert ta.item()==dff.iloc[inds[0]][\"label1\"]\n",
    "                ws.append(w)\n",
    "        \n",
    "        valid_loss=np.average(valid_loss,weights=ws)  \n",
    "                \n",
    "    return valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 20, 2\n",
    "optimizer = optim.AdamW(m.parameters(), lr=init_lr)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs, eta_min=eta_min)\n",
    "\n",
    "lrs = []\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    scheduler_cosine.step(epoch-1)\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "plt.plot(range(len(lrs)), lrs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del m,optimizer\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "def run(fold):\n",
    "\n",
    "    log_file = os.path.join(log_dir, f'{kernel_type}.txt')\n",
    "    model_file = os.path.join(model_dir, f'{kernel_type}_fold{fold}_best.pth')\n",
    "\n",
    "    train_ = df[df['fold'] != fold].reset_index(drop=True)\n",
    "    valid_ = df[df['fold'] == fold].reset_index(drop=True)\n",
    "    dataset_train = CLSDataset(train_, 'train', transform=transforms_train)\n",
    "    dataset_valid = CLSDataset(valid_, 'valid', transform=transforms_valid)\n",
    "    \n",
    "\n",
    "    class_counts = train_.label1.value_counts()\n",
    "    print(\"class_counts\",class_counts)\n",
    "    #class_w=[1/c for c in class_counts]\n",
    "    class_w=[1,2,4]\n",
    "    sample_train_weights=[class_w[i] for i in train_.label1.values]\n",
    "    sample_train_weights=[sample_train_weights[i]/train_.counts.values[i] for i in range(len(train_))]\n",
    "\n",
    "\n",
    "    nsamp=3000\n",
    "    sampler=WeightedRandomSampler(weights=sample_train_weights,num_samples=nsamp)\n",
    "\n",
    "    \n",
    "    #loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "    loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, num_workers=num_workers, drop_last=True,sampler=sampler)\n",
    "\n",
    "    loader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    model = TimmModel(backbone, pretrained=True)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=init_lr,weight_decay=1e-4)\n",
    "    scaler = torch.cuda.amp.GradScaler() if use_amp else None\n",
    "\n",
    "    metric_best = np.inf\n",
    "\n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, n_epochs, eta_min=eta_min)\n",
    "\n",
    "    print(len(dataset_train), len(dataset_valid))\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        print(time.ctime(), 'Epoch:', epoch)\n",
    "        train_loss = train_func(model, loader_train, optimizer, scaler)\n",
    "        scheduler_cosine.step(epoch-1)   \n",
    "        valid_loss = valid_func(model, loader_valid,valid_)\n",
    "    \n",
    "        metric = valid_loss\n",
    "\n",
    "        content = time.ctime() + ' ' + f'Fold {fold}, Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {train_loss:.5f}, valid loss: {valid_loss:.5f}, metric: {(metric):.6f}.'\n",
    "        print(content)\n",
    "        with open(log_file, 'a') as appender:\n",
    "            appender.write(content + '\\n')\n",
    "\n",
    "        if metric < metric_best:\n",
    "            print(f'metric_best ({metric_best:.6f} --> {metric:.6f}). Saving model ...')\n",
    "#             if not DEBUG:\n",
    "            torch.save(model.state_dict(), model_file)\n",
    "            metric_best = metric\n",
    "\n",
    "        # Save Last\n",
    "        if not DEBUG:\n",
    "            torch.save(\n",
    "                {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scaler_state_dict': scaler.state_dict() if scaler else None,\n",
    "                    'score_best': metric_best,\n",
    "                },\n",
    "                model_file.replace('_best', '_last')\n",
    "            )\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(0)\n",
    "#run(1)\n",
    "#run(2)\n",
    "#run(3)\n",
    "#run(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
