{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import timm\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import albumentations\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.cuda.amp as amp\n",
    "from torch.utils.data import  Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 20, 8\n",
    "device = torch.device('cuda')\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "        self.supports_masking = True\n",
    "\n",
    "        self.bias = bias\n",
    "        self.feature_dim = feature_dim\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        \n",
    "        weight = torch.zeros(feature_dim, 1)\n",
    "        nn.init.xavier_uniform_(weight)\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        \n",
    "        if bias:\n",
    "            self.b = nn.Parameter(torch.zeros(step_dim))\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        feature_dim = self.feature_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = torch.mm(\n",
    "            x.contiguous().view(-1, feature_dim), \n",
    "            self.weight\n",
    "        ).view(-1, step_dim)\n",
    "        \n",
    "        if self.bias:\n",
    "            eij = eij + self.b\n",
    "            \n",
    "        eij = torch.tanh(eij)\n",
    "        a = torch.exp(eij)\n",
    "        \n",
    "        if mask is not None:\n",
    "            a = a * mask\n",
    "\n",
    "        a = a / torch.sum(a, 1, keepdim=True) + 1e-10\n",
    "\n",
    "        weighted_input = x * torch.unsqueeze(a, -1)\n",
    "        return torch.sum(weighted_input, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = '0920_1bonev2_effv2s_224_15_6ch_augv2_mixupp5_drl3_rov1p2_bs8_lr23e5_eta23e6_50ep'\n",
    "load_kernel = None\n",
    "load_last = True\n",
    "\n",
    "n_folds = 5\n",
    "#backbone = 'tf_efficientnetv2_s.in21k_ft_in1k'\n",
    "#backbone=\"tf_efficientnetv2_b3.in21k_ft_in1k\"\n",
    "backbone=\"tf_efficientnetv2_b2.in1k\"\n",
    "\n",
    "image_size = 296\n",
    "\n",
    "n_slice_per_c = 90# bowel\n",
    "in_chans = 4\n",
    "\n",
    "init_lr = 2.0e-4\n",
    "eta_min = 0\n",
    "batch_size = 3\n",
    "drop_rate = 0.\n",
    "drop_rate_last = 0.3 #  0.1\n",
    "drop_path_rate = 0.2\n",
    "p_mixup = 0.4 #0 0.3\n",
    "p_rand_order_v1 = 0.2\n",
    "\n",
    "data_dir = './bowel'\n",
    "use_amp = True\n",
    "num_workers = 6\n",
    "out_dim = 2\n",
    "\n",
    "n_epochs = 60\n",
    "\n",
    "log_dir = './logs'\n",
    "model_dir = './models_bowel'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sronen/code/.venv/lib/python3.10/site-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "border_mode=cv2.BORDER_CONSTANT\n",
    "transforms_train = albumentations.Compose([\n",
    "    albumentations.Resize(image_size, image_size),\n",
    "    #albumentations.HorizontalFlip(p=0.3),\n",
    "    #albumentations.VerticalFlip(p=0.3),\n",
    "    #albumentations.Transpose(p=0.3),\n",
    "    albumentations.RandomBrightnessContrast(brightness_limit=0.05, contrast_limit=0.05, brightness_by_max=False, always_apply=False, p=0.3),\n",
    "\n",
    "    #border_mode=cv2.BORDER_REFLECT101\n",
    "    albumentations.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=15, border_mode=border_mode, p=0.5),\n",
    "\n",
    "    albumentations.OneOf([\n",
    "        albumentations.MotionBlur(blur_limit=3),\n",
    "        albumentations.MedianBlur(blur_limit=3),\n",
    "        albumentations.GaussianBlur(blur_limit=(1,3)),\n",
    "        albumentations.GaussNoise(var_limit=(3.0, 9.0)),\n",
    "    ], p=0.3),\n",
    "    #albumentations.OneOf([\n",
    "        #albumentations.OpticalDistortion(distort_limit=.3),\n",
    "    #    albumentations.GridDistortion(num_steps=4, distort_limit=.2),\n",
    "    #], p=0.3),\n",
    "    albumentations.GridDistortion(num_steps=4, distort_limit=.3),\n",
    "    albumentations.Cutout(max_h_size=int(image_size * 0.5), max_w_size=int(image_size * 0.5), num_holes=1, p=0.4),\n",
    "])\n",
    "\n",
    "transforms_valid = albumentations.Compose([\n",
    "    albumentations.Resize(image_size, image_size),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>hu</th>\n",
       "      <th>label</th>\n",
       "      <th>fold</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4701</th>\n",
       "      <td>9835</td>\n",
       "      <td>26866</td>\n",
       "      <td>208.00</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4702</th>\n",
       "      <td>9835</td>\n",
       "      <td>45852</td>\n",
       "      <td>340.00</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4703</th>\n",
       "      <td>9860</td>\n",
       "      <td>2625</td>\n",
       "      <td>126.00</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4704</th>\n",
       "      <td>9951</td>\n",
       "      <td>2731</td>\n",
       "      <td>286.00</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705</th>\n",
       "      <td>9960</td>\n",
       "      <td>42541</td>\n",
       "      <td>171.00</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4706</th>\n",
       "      <td>9961</td>\n",
       "      <td>2003</td>\n",
       "      <td>381.00</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4707</th>\n",
       "      <td>9961</td>\n",
       "      <td>63032</td>\n",
       "      <td>143.75</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4708</th>\n",
       "      <td>9980</td>\n",
       "      <td>40214</td>\n",
       "      <td>103.00</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4709</th>\n",
       "      <td>9980</td>\n",
       "      <td>40466</td>\n",
       "      <td>135.00</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4710</th>\n",
       "      <td>9983</td>\n",
       "      <td>10806</td>\n",
       "      <td>168.00</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id  series_id      hu   label  fold  counts\n",
       "4701        9835      26866  208.00  [0, 0]     3       2\n",
       "4702        9835      45852  340.00  [0, 0]     3       2\n",
       "4703        9860       2625  126.00  [0, 0]     2       1\n",
       "4704        9951       2731  286.00  [0, 0]     2       1\n",
       "4705        9960      42541  171.00  [0, 0]     0       1\n",
       "4706        9961       2003  381.00  [0, 0]     2       2\n",
       "4707        9961      63032  143.75  [0, 0]     2       2\n",
       "4708        9980      40214  103.00  [0, 0]     2       2\n",
       "4709        9980      40466  135.00  [0, 0]     2       2\n",
       "4710        9983      10806  168.00  [0, 0]     1       1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "organ_dict = {\n",
    "    0: 'bowel',\n",
    "    1: 'extravasation',\n",
    "}\n",
    "\n",
    "df_p = pd.read_csv('/kaggle/input/rsna-2023-abdominal-trauma-detection/train.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_s=pd.read_csv('/kaggle/input/rsna-2023-abdominal-trauma-detection/train_series_meta.csv')\n",
    "\n",
    "df_p['fold'] = -1\n",
    "kf = KFold(5,shuffle=True,random_state=42)\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(df_p,df_p)):\n",
    "    df_p.loc[valid_idx, 'fold'] = fold\n",
    "\n",
    "\n",
    "#df_healthy=df_p[df_p[\"any_injury\"]==0].sample(758)\n",
    "#df_injured=df_p[(df_p[\"kidney_healthy\"]==0) | (df_p[\"liver_healthy\"]==0)| (df_p[\"spleen_healthy\"]==0) | (df_p[\"bowel_healthy\"]==0)]\n",
    "#print(len(df_injured),len(df_healthy))\n",
    "#df_p1=pd.concat((df_healthy,df_injured))\n",
    "\n",
    "\n",
    "df=df_p.merge(df_s,on=\"patient_id\")\n",
    "df[\"count\"]=df.groupby([\"patient_id\"])[\"patient_id\"].transform(\"count\")\n",
    "\n",
    "\n",
    "pid=[]\n",
    "sid = []\n",
    "cs = []\n",
    "label = []\n",
    "label1=[]\n",
    "fold = []\n",
    "hu=[]\n",
    "counts=[]\n",
    "for row in df.to_dict(orient=\"records\"):\n",
    "        pid.append(row[\"patient_id\"])\n",
    "        sid.append(row[\"series_id\"])\n",
    "        hu.append(row[\"aortic_hu\"])\n",
    "        la=[row[\"bowel_injury\"],row[\"extravasation_injury\"]]\n",
    "        label.append(la)\n",
    "        fold.append(row[\"fold\"])\n",
    "        counts.append(row[\"count\"])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'patient_id': pid,\n",
    "    'series_id': sid,\n",
    "    'hu':hu,\n",
    "    'label': label,\n",
    "    'fold': fold,\n",
    "    'counts':counts,\n",
    "})\n",
    "\n",
    "df = df.sample(16).reset_index(drop=True) if DEBUG else df\n",
    "\n",
    "df.tail(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLSDataset(Dataset):\n",
    "    def __init__(self, df, mode, transform):\n",
    "\n",
    "        self.df = df.reset_index()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        images = []\n",
    "        \n",
    "        filepath=os.path.join(data_dir, f'{row.patient_id}_{row.series_id}.npz')\n",
    "        data = np.load(filepath)\n",
    "        image3d=data['arr_0'] # slice,channel,H,W\n",
    "        \n",
    "        for ind in list(range(n_slice_per_c)):\n",
    "            image=image3d[ind,...].transpose(1,2,0).astype(np.uint8)\n",
    "            image = self.transform(image=image)['image']\n",
    "            image = image.transpose(2, 0, 1).astype(np.float32) / 255.\n",
    "            images.append(image)\n",
    "        images = np.stack(images, 0)\n",
    "\n",
    "   \n",
    "\n",
    "        if self.mode != 'test':\n",
    "            images = torch.tensor(images).float()\n",
    "            labels=data['arr_1']  # slice\n",
    "            labels = torch.tensor(labels).float()\n",
    "            counts=torch.tensor([row.counts]*n_slice_per_c).float()\n",
    "            \n",
    "            #images[...]=0.\n",
    "            #images[:,:,:,:3]=labels[:,None,None,:]\n",
    "            #images[:,0,0,:3]=labels[:,:]\n",
    "\n",
    "         \n",
    "            \n",
    "            if self.mode == 'train' and random.random() < p_rand_order_v1:\n",
    "                indices = torch.randperm(images.size(0))\n",
    "                images = images[indices]\n",
    "                counts=counts[indices]\n",
    "\n",
    "            return images, labels,counts\n",
    "        else:\n",
    "            return torch.tensor(images).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 20,8\n",
    "\n",
    "df_show = df\n",
    "dataset_show = CLSDataset(df_show, 'train', transform=transforms_train)\n",
    "loader_show = torch.utils.data.DataLoader(dataset_show, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(2,6)\n",
    "for p in range(6):\n",
    "    idx = p * 20\n",
    "    imgs, lbl,_ = dataset_show[idx]\n",
    "    sel=7\n",
    "    axarr[0, p].imshow(255*imgs[sel][1],cmap=\"gray\")\n",
    "    axarr[1, p].imshow(imgs[sel][-1],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormedLinear(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(NormedLinear, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(in_features, out_features))\n",
    "        self.weight.data.uniform_(-1, 1).renorm_(2, 1, 1e-5).mul_(1e5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.normalize(x, dim=1).mm(F.normalize(self.weight, dim=0))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimmModel(nn.Module):\n",
    "    def __init__(self, backbone, pretrained=False):\n",
    "        super(TimmModel, self).__init__()\n",
    "\n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=in_chans,\n",
    "            num_classes=out_dim,\n",
    "            features_only=False,\n",
    "            drop_rate=drop_rate,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "\n",
    "        if 'efficient' in backbone:\n",
    "            hdim = self.encoder.conv_head.out_channels\n",
    "            self.encoder.classifier = nn.Identity()\n",
    "        elif 'convnext' in backbone:\n",
    "            hdim = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Identity()\n",
    "\n",
    "\n",
    "        self.lstm = nn.LSTM(hdim, 512, num_layers=1, dropout=drop_rate, bidirectional=True, batch_first=True)\n",
    "        self.head = nn.Linear(2048, out_dim)\n",
    "\n",
    "    def forward(self, x):  # (bs, nslice, ch, sz, sz)\n",
    "        bs = x.shape[0]\n",
    "        x = x.view(bs * n_slice_per_c, in_chans, image_size, image_size)\n",
    "        feat = self.encoder(x)\n",
    "        feat = feat.view(bs, n_slice_per_c, -1)\n",
    "        feat, _ = self.lstm(feat) #(B,L,F)\n",
    "        max_pool, _ = torch.max(feat, 1)\n",
    "        att_pool = self.attention(feat, mask=None)  \n",
    "        conc = torch.cat((max_pool, att_pool), 1)  \n",
    "\n",
    "        #feat = feat.contiguous().view(bs * n_slice_per_c, -1)\n",
    "        logits = self.head(conc)\n",
    "        #feat = feat.view(bs, n_slice_per_c,out_dim).contiguous()\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = TimmModel(backbone)\n",
    "m(torch.rand(2, n_slice_per_c, in_chans, image_size, image_size)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(m,(1,n_slice_per_c,in_chans,image_size,image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = nn.CrossEntropyLoss(reduction='none', label_smoothing=0.0)\n",
    "\n",
    "mapping = torch.tensor([1., 2.]).cuda()\n",
    "mapping=mapping/torch.mean(mapping)\n",
    "\n",
    "def criterion(logits, targets,counts=None,weights=None):\n",
    "    b=logits.shape[0]\n",
    "    logits=logits.view(-1,out_dim)\n",
    "    targets=targets.view(-1,out_dim)\n",
    "    loss = ce(logits, targets)\n",
    "    \n",
    "    if weights is not None:\n",
    "        w=torch.matmul(targets,mapping)\n",
    "    else:\n",
    "        w=torch.ones(b).float().cuda()\n",
    "    if counts is not None:\n",
    "        counts=counts.view(-1)\n",
    "        w=w/counts\n",
    "    loss=loss.reshape((b,-1))\n",
    "    w=w.reshape((b,-1))\n",
    "    loss=torch.mean(loss,dim=1)\n",
    "\n",
    "    w=torch.mean(w,dim=1)\n",
    "    return loss,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.beta import Beta\n",
    "beta=Beta(torch.tensor([0.2]),torch.tensor([0.2]))\n",
    "\n",
    "def mix_up(images1,labels1):\n",
    "    # Unpack two datasets\n",
    "    batch_size = images1.shape[0]\n",
    "    # Sample lambda and reshape it to do the mixup\n",
    "    l = beta.sample(torch.Size([batch_size])).cuda()\n",
    "    x_l = l.reshape((batch_size, 1, 1, 1,1))\n",
    "    y_l = l.reshape((batch_size, 1,1))\n",
    "    idx = torch.randperm(batch_size).cuda()\n",
    "    images2=images1[idx,...]\n",
    "    labels2=labels1[idx,...]\n",
    "    # Perform mixup on both images and labels by combining a pair of images/labels\n",
    "    # (one from each dataset) into one image/label\n",
    "    images = images1 * x_l + images2 * (1 - x_l)\n",
    "    labels = labels1 * y_l + labels2 * (1 - y_l)\n",
    "    return (images, labels)\n",
    "\n",
    "\n",
    "def train_func(model, loader_train, optimizer, scaler=None):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    ws=[]\n",
    "    bar = tqdm(loader_train)\n",
    "    for images, targets,_ in bar:\n",
    "        optimizer.zero_grad()\n",
    "        images = images.cuda()\n",
    "        targets = targets.cuda()\n",
    "  \n",
    "        if random.random() < p_mixup:\n",
    "            images, targets = mix_up(images, targets)\n",
    "\n",
    "        if use_amp:\n",
    "            with amp.autocast():\n",
    "                logits = model(images)\n",
    "                loss,w = criterion(logits, targets)\n",
    "                loss1=torch.mean(loss*w)\n",
    "            scaler.scale(loss1).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            train_loss.extend(loss.detach().cpu())\n",
    "\n",
    "        else:\n",
    "            logits = model(images)\n",
    "            loss,w = criterion(logits, targets)\n",
    "            loss1=torch.mean(loss*w)\n",
    "            loss1.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.extend(loss.detach().cpu())\n",
    "\n",
    "            \n",
    "        ws.extend(w.detach().cpu())\n",
    "        bar.set_description(f'smth:{np.average(train_loss[-100:],weights=ws[-100:]):.4f}')\n",
    "\n",
    "    return np.average(train_loss,weights=ws)\n",
    "\n",
    "\n",
    "def valid_func(model, loader_valid,dff):\n",
    "    model.eval()\n",
    "    valid_loss=[]\n",
    "    valid_loss_progress = []\n",
    "    outputs = []\n",
    "    tgs=[]\n",
    "    ws=[]\n",
    "    ws_progress=[]\n",
    "    bar = tqdm(loader_valid)\n",
    "    with torch.no_grad():\n",
    "        for images, targets,counts in bar:\n",
    "            images = images.cuda()\n",
    "            targets = targets.cuda()\n",
    "            counts=counts.cuda()\n",
    "\n",
    "            #if use_amp:\n",
    "            #    with amp.autocast():\n",
    "            \n",
    "            logits = model(images)\n",
    "            blogits=torch.mean(logits,dim=1) # average logits across slices\n",
    "            loss,w=criterion(logits,targets,counts,mapping)\n",
    "\n",
    "            ws_progress.extend(w.cpu())\n",
    "            valid_loss_progress.extend(loss.cpu())\n",
    "            out=torch.unbind(blogits,dim=0)   \n",
    "            outputs.extend(out)\n",
    "            tt=targets[:,0,:] # first slice\n",
    "            tgs.extend(torch.unbind(tt,dim=0))\n",
    "            bar.set_description(f'smth:{np.average(valid_loss_progress[-100:],weights=ws_progress[-100:]):.4f}')\n",
    "        for pid in dff[\"patient_id\"].unique():\n",
    "            for c in range(3):\n",
    "                #print(\"patient\",pid,\"organ\",c)\n",
    "                inds=dff[(dff[\"patient_id\"]==pid) & (dff[\"c\"]==c)].index.values\n",
    "                #print(pid,c,inds[0],dff.iloc[inds[0]])\n",
    "                la=torch.mean(torch.stack([outputs[i] for i in inds]),dim=0) # average logits across up to two series per patient\n",
    "                ta=tgs[inds[0]]\n",
    "\n",
    "                loss = ce(la[None,:], ta[None,:])\n",
    "                #print(\"fpatient id {pid}, organ {c}, {la} , {ta}, {loss}\")\n",
    "                valid_loss.append(loss.item())\n",
    "                ta=torch.argmax(ta)\n",
    "                w=mapping[ta].item()\n",
    "                #print(ta.item(),dff.iloc[inds[0]][\"label1\"])\n",
    "                assert ta.item()==dff.iloc[inds[0]][\"label1\"]\n",
    "                ws.append(w)\n",
    "        \n",
    "        valid_loss=np.average(valid_loss,weights=ws)  \n",
    "                \n",
    "    return valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 20, 2\n",
    "optimizer = optim.AdamW(m.parameters(), lr=init_lr)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs, eta_min=eta_min)\n",
    "\n",
    "lrs = []\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    scheduler_cosine.step(epoch-1)\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "plt.plot(range(len(lrs)), lrs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del m,optimizer\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "def run(fold):\n",
    "\n",
    "    log_file = os.path.join(log_dir, f'{kernel_type}.txt')\n",
    "    model_file = os.path.join(model_dir, f'{kernel_type}_fold{fold}_best.pth')\n",
    "\n",
    "    train_ = df[df['fold'] != fold].reset_index(drop=True)\n",
    "    valid_ = df[df['fold'] == fold].reset_index(drop=True)\n",
    "    dataset_train = CLSDataset(train_, 'train', transform=transforms_train)\n",
    "    dataset_valid = CLSDataset(valid_, 'valid', transform=transforms_valid)\n",
    "    \n",
    "\n",
    "    class_counts = train_.label1.value_counts()\n",
    "    print(\"class_counts\",class_counts)\n",
    "    #class_w=[1/c for c in class_counts]\n",
    "    class_w=[1,2,4]\n",
    "    sample_train_weights=[class_w[i] for i in train_.label1.values]\n",
    "    sample_train_weights=[sample_train_weights[i]/train_.counts.values[i] for i in range(len(train_))]\n",
    "\n",
    "\n",
    "    nsamp=3000\n",
    "    sampler=WeightedRandomSampler(weights=sample_train_weights,num_samples=nsamp)\n",
    "\n",
    "    \n",
    "    #loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "    loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, num_workers=num_workers, drop_last=True,sampler=sampler)\n",
    "\n",
    "    loader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    model = TimmModel(backbone, pretrained=True)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=init_lr,weight_decay=1e-4)\n",
    "    scaler = torch.cuda.amp.GradScaler() if use_amp else None\n",
    "\n",
    "    metric_best = np.inf\n",
    "\n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, n_epochs, eta_min=eta_min)\n",
    "\n",
    "    print(len(dataset_train), len(dataset_valid))\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        print(time.ctime(), 'Epoch:', epoch)\n",
    "        train_loss = train_func(model, loader_train, optimizer, scaler)\n",
    "        scheduler_cosine.step(epoch-1)   \n",
    "        valid_loss = valid_func(model, loader_valid,valid_)\n",
    "    \n",
    "        metric = valid_loss\n",
    "\n",
    "        content = time.ctime() + ' ' + f'Fold {fold}, Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {train_loss:.5f}, valid loss: {valid_loss:.5f}, metric: {(metric):.6f}.'\n",
    "        print(content)\n",
    "        with open(log_file, 'a') as appender:\n",
    "            appender.write(content + '\\n')\n",
    "\n",
    "        if metric < metric_best:\n",
    "            print(f'metric_best ({metric_best:.6f} --> {metric:.6f}). Saving model ...')\n",
    "#             if not DEBUG:\n",
    "            torch.save(model.state_dict(), model_file)\n",
    "            metric_best = metric\n",
    "\n",
    "        # Save Last\n",
    "        if not DEBUG:\n",
    "            torch.save(\n",
    "                {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scaler_state_dict': scaler.state_dict() if scaler else None,\n",
    "                    'score_best': metric_best,\n",
    "                },\n",
    "                model_file.replace('_best', '_last')\n",
    "            )\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(0)\n",
    "#run(1)\n",
    "#run(2)\n",
    "#run(3)\n",
    "#run(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
