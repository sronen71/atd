{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install+Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "sys.path.append('/kaggle/input/rsna-2023-abdominal-trauma')\n",
    "sys.path.append('/kaggle/input/atd-packages/mypackages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from timeit import default_timer as timer\n",
    "from utils import get_seg_model,load_dicom_folder,resize3d,visualize,get_crops\n",
    "from utils import LSKModel,BowelModel,PENet\n",
    "from utils import score,create_training_solution\n",
    "from matplotlib import pyplot as plt\n",
    "import gc\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'local' #submit #local\n",
    "models_dir=\"/kaggle/input/rsna-2023-abdominal-trauma\"\n",
    "if mode =='local':\n",
    "    image_dir  = '/kaggle/input/rsna-2023-abdominal-trauma-detection/train_images'\n",
    "  \n",
    "    df_meta = pd.read_csv('/kaggle/input/rsna-2023-abdominal-trauma-detection/train_series_meta.csv')\n",
    "    df_p = pd.read_csv('/kaggle/input/rsna-2023-abdominal-trauma-detection/train.csv') \n",
    "    kf = KFold(5,shuffle=True,random_state=42)\n",
    "    df_p[\"fold\"]=-1\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(df_p,df_p)):\n",
    "        df_p.loc[valid_idx, 'fold'] = fold\n",
    "\n",
    "    df_p=df_p[df_p[\"fold\"]==0]    \n",
    "    df_p=df_p.sort_values(by=\"patient_id\").reset_index(drop=True)  \n",
    "    df_meta= df_meta.merge(df_p[\"patient_id\"],on=\"patient_id\")\n",
    "\n",
    "else:\n",
    "    image_dir = '/kaggle/input/rsna-2023-abdominal-trauma-detection/test_images'\n",
    "    \n",
    "    df_meta = pd.read_csv('/kaggle/input/rsna-2023-abdominal-trauma-detection/test_series_meta.csv')\n",
    "  \n",
    "\n",
    "df_meta.sort_values(by=[\"patient_id\",\"aortic_hu\"],inplace=True)\n",
    "df_meta.set_index([\"patient_id\",\"series_id\"],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode==\"local\":\n",
    "    select_models=[0]\n",
    "else:\n",
    "    select_models=[0,1,2,3,4]\n",
    "\n",
    "def load_seg_models(models_dir,kernel):\n",
    "    models=[]\n",
    "    for ifold in range(5):\n",
    "        model=get_seg_model(pretrained=False)\n",
    "        model.load_state_dict(torch.load(f\"{models_dir}/{kernel}_fold{ifold}_best.pth\"))\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def load_lsk_models(models_dir,kernel,backbone):\n",
    "    models=[]\n",
    "    for ifold in select_models:\n",
    "        model=LSKModel(backbone,pretrained=False)\n",
    "        model.load_state_dict(torch.load(f\"{models_dir}/{kernel}_fold{ifold}_best.pth\"))\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "\n",
    "def load_bowel_models(models_dir,kernel,backbone):\n",
    "    models=[]\n",
    "    for ifold in select_models:\n",
    "        model=BowelModel(backbone,pretrained=False)\n",
    "        model.load_state_dict(torch.load(f\"{models_dir}/{kernel}_fold{ifold}_best.pth\"))\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def load_final_models(models_dir):\n",
    "    models=[]\n",
    "    for ifold in select_models:\n",
    "        model=PENet()\n",
    "        model.load_state_dict(torch.load(f\"{models_dir}/lstm _fold{ifold}_best.pth\"))\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "\n",
    "models_seg_dir=os.path.join(models_dir,\"models_seg\")\n",
    "kernel_seg = 'timm3d_res18d_unet4b_128_128_128_dsv2_flip12_shift333p7_gd1p5_bs4_lr3e4_20x50ep'\n",
    "seg_models=load_seg_models(models_seg_dir,kernel_seg)\n",
    "\n",
    "models_lsk_dir=os.path.join(models_dir,\"models_cls\")\n",
    "kernel_lsk = '0920_1bonev2_effv2s_224_15_6ch_augv2_mixupp5_drl3_rov1p2_bs8_lr23e5_eta23e6_50ep'\n",
    "backbone_lsk1=\"tf_efficientnetv2_b2.in1k\"\n",
    "lsk_models=load_lsk_models(models_lsk_dir,kernel_lsk,backbone_lsk1)\n",
    "\n",
    "models_bowel_dir=os.path.join(models_dir,\"models_bowel\")\n",
    "kernel_bowel = '0920_1bonev2_effv2s_224_15_6ch_augv2_mixupp5_drl3_rov1p2_bs8_lr23e5_eta23e6_50ep'\n",
    "backbone_bowel1=\"tf_efficientnetv2_b0.in1k\"\n",
    "bowel_models=load_bowel_models(models_bowel_dir,kernel_bowel,backbone_bowel1)\n",
    "\n",
    "models_final_dir=os.path.join(models_dir,\"models_stage3_all\")\n",
    "final_models=load_final_models(models_final_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_seg_size = [128, 128, 128]\n",
    "#image_check_dir=\"./preprocessed1\"\n",
    "def resize_image(image_full,sorted_slices,series_id):    \n",
    "    image1=resize3d(image_full,sorted_slices,image_seg_size)\n",
    "    image=(image1/255.).astype(np.float32)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def infer_mask(image,models,vis=False):\n",
    "    with torch.cuda.amp.autocast():\n",
    "        with torch.no_grad():\n",
    "            #image=torch.from_numpy(image).cuda()\n",
    "            image=image[None,...]\n",
    "            pred_masks = []\n",
    "            for model in models:\n",
    "                model.cuda()\n",
    "                model.eval()\n",
    "                pmask = model(image).squeeze()\n",
    "                pmask=nn.Softmax(dim=0)(pmask)\n",
    "                pred_masks.append(pmask)\n",
    "    mask = torch.stack(pred_masks).mean(0)\n",
    "    mask=torch.argmax(mask,dim=0)\n",
    "    mask=mask.numpy(force=True).astype(np.uint8)\n",
    "  \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_lsk(image_crops,models,nslice=24):\n",
    "    lsk_dict={0:\"liver\",1:\"spleen\",2:\"kidney\"}\n",
    "    results={}\n",
    "    with torch.cuda.amp.autocast(enabled=True):\n",
    "        with torch.no_grad():\n",
    "            for iorgan in range(3): #liver,spleen,kidney\n",
    "                inds=list(range(iorgan*nslice,(iorgan+1)*nslice))\n",
    "                images=image_crops[inds,...]\n",
    "                images=torch.from_numpy(images).float().cuda()\n",
    "                images=images[None,...]\n",
    "                mlogits=[]\n",
    "                for model in models:\n",
    "                    model.cuda()\n",
    "                    model.eval()\n",
    "                    logits = model(images).mean(dim=1).squeeze()\n",
    "                    logits = logits.numpy(force=True)\n",
    "                    mlogits.append(logits)\n",
    "                    #print(logits)\n",
    "                results[lsk_dict[iorgan]]=np.mean(np.stack(mlogits),axis=0)\n",
    "    return results\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_be(image_crops,models,start=3*24,nslice=128):\n",
    "    results={}\n",
    "    with torch.cuda.amp.autocast(enabled=True):\n",
    "        with torch.no_grad():\n",
    "            inds=list(range(start,start+nslice))\n",
    "            images=image_crops[inds,...]\n",
    "            images=torch.from_numpy(images).cuda()\n",
    "            images=images[None,...]\n",
    "            mlogits=[]\n",
    "            for model in models:\n",
    "                model.cuda()\n",
    "                model.eval()\n",
    "                logits = model(images)[1].squeeze()\n",
    "                logits = logits.numpy(force=True)\n",
    "                mlogits.append(logits)\n",
    "            mlogits=np.mean(np.stack(mlogits),axis=0)\n",
    "            results[\"bowel\"]=mlogits\n",
    "            #print(mlogits)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_final(data,models):\n",
    "    results={\"liver\":[],\"spleen\":[],\"kidney\":[],\"bowel\":[],\"extravasation\":[]}\n",
    "    probs={}\n",
    "    with torch.cuda.amp.autocast(enabled=True):\n",
    "        with torch.no_grad():\n",
    "            for k in data:\n",
    "                data[k]=torch.from_numpy(data[k]).float().cuda()[None,...]\n",
    "            for model in models:\n",
    "                model.cuda()\n",
    "                model.eval()\n",
    "                logits = model(data)\n",
    "                for k in logits:\n",
    "                    results[k].append(logits[k].squeeze())\n",
    "    for k in results:\n",
    "        results[k]=torch.mean(torch.stack(results[k]),axis=0)\n",
    "        if k in [\"liver\",\"spleen\",\"kidney\"]:\n",
    "            probs[k]=nn.Softmax(dim=0)(results[k].float())\n",
    "        else:\n",
    "            probs[k]=nn.Sigmoid()(results[k].float())\n",
    "        probs[k]=probs[k].numpy(force=True)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_lsk(cropped_images):\n",
    "    f, axarr = plt.subplots(2,4)\n",
    "    p=0\n",
    "    for organ in range(3):\n",
    "        imgs=cropped_images[list(range(organ*24,(organ+1)*24))]\n",
    "        sel=7\n",
    "        axarr[0, p].imshow(255*imgs[sel][1],cmap=\"gray\")\n",
    "        axarr[1, p].imshow(imgs[sel][-1],cmap=\"gray\")\n",
    "        p+=1\n",
    "    imgs=cropped_images[(3*24):]\n",
    "    sel=65\n",
    "    axarr[0, p].imshow(255*imgs[sel][1],cmap=\"gray\")\n",
    "    axarr[1, p].imshow(imgs[sel][-1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis=False\n",
    "mask_dir=\"./preprocessed1\"\n",
    "crops_lsk_dir=\"./preprocessed2\"\n",
    "crops_bowel_dir=\"./bowel\"\n",
    "def analyze_dicom(image_full,image,patient_id,series_id):\n",
    "    mask=infer_mask(image,seg_models,vis=vis)\n",
    "    if vis:\n",
    "        visualize(image,mask)\n",
    "    #mask_file=os.path.join(mask_dir,f\"{series_id}_mask.npy\")\n",
    "    #check_mask=np.load(mask_file)\n",
    "    #mask_diff=mask-check_mask\n",
    "    #df_describe = pd.DataFrame(mask_diff.flatten()[:,None])\n",
    "    #print(\"mask diff\",df_describe.describe())\n",
    "    #visualize(mask_diff,mask_diff)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    cropped_images = get_crops(image_full,mask) \n",
    "    del image_full\n",
    "    del mask\n",
    "    if vis:\n",
    "        visualize_lsk(cropped_images)\n",
    "        lsk_filepath=os.path.join(crops_lsk_dir, f'{patient_id}_{series_id}.npz')\n",
    "        bowel_filepath=os.path.join(crops_bowel_dir,f'{patient_id}_{series_id}.npz')\n",
    "        image_check_lsk = np.load(lsk_filepath)['arr_0'] # slice,channel,H,W\n",
    "        image_check_bowel = np.load(bowel_filepath)['arr_0'] # slice,channel,H,W\n",
    "        image_check=np.concatenate((image_check_lsk,image_check_bowel),axis=0)\n",
    "        diff=image_check-cropped_images\n",
    "\n",
    "        visualize_lsk(diff)\n",
    "        print(diff.shape)\n",
    "        df_describe = pd.DataFrame(diff[:72,0:3,:,:].flatten()[:,None])\n",
    "        print(df_describe.describe())\n",
    "\n",
    "        #df_describe = pd.DataFrame(diff[72:,0:3,:,:].flatten()[:,None])\n",
    "        #print(df_describe.describe())\n",
    "\n",
    "    cropped_images=cropped_images.astype(np.float32)/255.\n",
    "    lsk_logits=infer_lsk(cropped_images,lsk_models)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    be_logits=infer_be(cropped_images,bowel_models)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    logits=lsk_logits\n",
    "    logits.update(**be_logits)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegTestDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        patient_id=row.patient_id\n",
    "        series_id=row.series_id\n",
    "        image_folder=f\"{image_dir}/{int(patient_id)}/{int(series_id)}\"\n",
    "        image_full,sorted_slices=load_dicom_folder(image_folder,None)\n",
    "        image=resize_image(image_full,sorted_slices,series_id)\n",
    "\n",
    "        return {\"image_full\":image_full,\"image\":torch.tensor(image).float(),\"patient_id\":patient_id,\"series_id\":series_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run(num=None):\n",
    "    submit_df_data=[]\n",
    "    df_meta_run=df_meta.copy()\n",
    "    if num is not None:\n",
    "        df_meta_run=df_meta_run.iloc[:num]\n",
    "    series_logits=[]\n",
    "    dataset_seg = SegTestDataset(df_meta_run)\n",
    "    loader_seg = DataLoader(dataset_seg, batch_size=1, shuffle=False, num_workers=2,pin_memory=True)\n",
    "    bar = tqdm(loader_seg)\n",
    "    for batch_id, data in enumerate(bar):\n",
    "        image_full=data[\"image_full\"]\n",
    "        image=data[\"image\"]\n",
    "        patient_id=data[\"patient_id\"]\n",
    "        series_id=data[\"series_id\"]\n",
    "\n",
    "        image = image.cuda()\n",
    "        image_full=image_full.squeeze().numpy()\n",
    "        del data\n",
    "        gc.collect()\n",
    "        patient_id=patient_id.squeeze().item()\n",
    "        series_id=series_id.squeeze().item()\n",
    "        logits=analyze_dicom(image_full,image,patient_id,series_id)\n",
    "        series_logits.append({\n",
    "                    'patient_id': patient_id,\n",
    "                    'series_id' : series_id,\n",
    "                    'liver' : logits[\"liver\"],\n",
    "                    'spleen': logits[\"spleen\"],\n",
    "                    'kidney'    : logits[\"kidney\"],\n",
    "                    'bowel'   : logits[\"bowel\"],\n",
    "                })\n",
    "    series_logits=pd.DataFrame(series_logits)\n",
    "    df_meta_run=df_meta_run.reset_index()\n",
    "    series_logits=series_logits.merge(df_meta_run,on=[\"patient_id\",\"series_id\"])\n",
    "    for patient_id, group in series_logits.groupby(\"patient_id\"):\n",
    "        plogits={\"liver\":[],\"spleen\":[],\"kidney\":[],\"bowel\":[]}\n",
    "        for ind,row in group.iterrows():\n",
    "            for k in plogits:\n",
    "                logits[k]=np.concatenate((row[k],np.array((row.aortic_hu,))))\n",
    "                plogits[k].append(logits[k])\n",
    "        if len(group)==1:\n",
    "            for k in plogits:\n",
    "                plogits[k].append(plogits[k][0])\n",
    "        for k in plogits:\n",
    "            plogits[k]=np.stack(plogits[k])\n",
    "        \n",
    "        probs=infer_final(plogits,final_models)\n",
    "        for k in probs:\n",
    "            probs[k]=np.clip(probs[k],0.0001,.9999)\n",
    "        submit_df_data.append({\n",
    "                    'patient_id': patient_id,\n",
    "                    'series_id' : series_id,\n",
    "                    'liver_healthy' : probs[\"liver\"][0],\n",
    "                    'liver_low'     : probs[\"liver\"][1],\n",
    "                    'liver_high'    : probs[\"liver\"][2],\n",
    "                    'spleen_healthy': probs[\"spleen\"][0],\n",
    "                    'spleen_low'    : probs[\"spleen\"][1],\n",
    "                    'spleen_high'   : probs[\"spleen\"][2],\n",
    "                    'kidney_healthy': probs[\"kidney\"][0],\n",
    "                    'kidney_low'    : probs[\"kidney\"][1],\n",
    "                    'kidney_high'   : probs[\"kidney\"][2],\n",
    "\n",
    "                    'bowel_healthy'        : 1-probs[\"bowel\"],\n",
    "                    'bowel_injury'         : probs[\"bowel\"],\n",
    "                    'extravasation_healthy': 1-probs[\"extravasation\"],\n",
    "                    'extravasation_injury' : probs[\"extravasation\"],\n",
    "                })\n",
    "        \n",
    "    submit_col=[\n",
    "            'patient_id',\n",
    "            'bowel_healthy','bowel_injury','extravasation_healthy','extravasation_injury','kidney_healthy','kidney_low','kidney_high','liver_healthy','liver_low','liver_high','spleen_healthy','spleen_low','spleen_high'\n",
    "        ]\n",
    "\n",
    "    submit_df = pd.DataFrame(submit_df_data)\n",
    "    submit_df = submit_df[submit_col]\n",
    "    submit_df.to_csv('submission.csv',index=False)\n",
    "    submit_col=[\n",
    "            'patient_id',\n",
    "            'bowel_healthy','bowel_injury','extravasation_healthy','extravasation_injury','kidney_healthy','kidney_low','kidney_high','liver_healthy','liver_low','liver_high','spleen_healthy','spleen_low','spleen_high'\n",
    "        ]\n",
    "\n",
    "    submit_df = pd.DataFrame(submit_df_data)\n",
    "    submit_df = submit_df[submit_col]\n",
    "    submit_df.to_csv('submission.csv',index=False)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/950 [00:24<1:18:13,  4.97s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sronen/code/atd/inference-atd/inference-atd.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sronen/code/atd/inference-atd/inference-atd.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RUN\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sronen/code/atd/inference-atd/inference-atd.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mif\u001b[39;00m RUN:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sronen/code/atd/inference-atd/inference-atd.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     run()\n",
      "\u001b[1;32m/home/sronen/code/atd/inference-atd/inference-atd.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sronen/code/atd/inference-atd/inference-atd.ipynb#X22sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     patient_id\u001b[39m=\u001b[39mpatient_id\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sronen/code/atd/inference-atd/inference-atd.ipynb#X22sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     series_id\u001b[39m=\u001b[39mseries_id\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sronen/code/atd/inference-atd/inference-atd.ipynb#X22sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     logits\u001b[39m=\u001b[39manalyze_dicom(image_full,image,patient_id,series_id)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sronen/code/atd/inference-atd/inference-atd.ipynb#X22sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     series_logits\u001b[39m.\u001b[39mappend({\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sronen/code/atd/inference-atd/inference-atd.ipynb#X22sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mpatient_id\u001b[39m\u001b[39m'\u001b[39m: patient_id,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sronen/code/atd/inference-atd/inference-atd.ipynb#X22sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mseries_id\u001b[39m\u001b[39m'\u001b[39m : series_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sronen/code/atd/inference-atd/inference-atd.ipynb#X22sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mbowel\u001b[39m\u001b[39m'\u001b[39m   : logits[\u001b[39m\"\u001b[39m\u001b[39mbowel\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sronen/code/atd/inference-atd/inference-atd.ipynb#X22sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m             })\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sronen/code/atd/inference-atd/inference-atd.ipynb#X22sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m series_logits\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame(series_logits)\n",
      "\u001b[1;32m/home/sronen/code/atd/inference-atd/inference-atd.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sronen/code/atd/inference-atd/inference-atd.ipynb#X22sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m gc\u001b[39m.\u001b[39mcollect()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sronen/code/atd/inference-atd/inference-atd.ipynb#X22sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sronen/code/atd/inference-atd/inference-atd.ipynb#X22sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m cropped_images \u001b[39m=\u001b[39m get_crops(image_full,mask) \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sronen/code/atd/inference-atd/inference-atd.ipynb#X22sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mdel\u001b[39;00m image_full\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sronen/code/atd/inference-atd/inference-atd.ipynb#X22sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mdel\u001b[39;00m mask\n",
      "File \u001b[0;32m/kaggle/input/rsna-2023-abdominal-trauma/utils.py:331\u001b[0m, in \u001b[0;36mget_crops\u001b[0;34m(image_full, msk)\u001b[0m\n\u001b[1;32m    329\u001b[0m     threads[cid]\u001b[39m.\u001b[39mstart()\n\u001b[1;32m    330\u001b[0m \u001b[39mfor\u001b[39;00m cid \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[0;32m--> 331\u001b[0m     threads[cid]\u001b[39m.\u001b[39;49mjoin()\n\u001b[1;32m    332\u001b[0m cropped_images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(cropped_images, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    333\u001b[0m \u001b[39mreturn\u001b[39;00m cropped_images\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   1097\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   1117\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RUN=True\n",
    "if RUN:\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode==\"local\":\n",
    "     submission=pd.read_csv(\"submission.csv\")\n",
    "     \n",
    "     solution=create_training_solution(df_p)\n",
    "     solution=solution.merge(submission[[\"patient_id\"]],on=\"patient_id\")\n",
    "     valid_loss,group_losses = score(solution.copy(),submission,'patient_id')\n",
    "     print(\"# patients\",len(solution))\n",
    "     print(group_losses)\n",
    "     print(\"valid_loss\",valid_loss)\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
